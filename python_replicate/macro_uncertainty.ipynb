{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/yaolangzhong/Nottingham_Replication/original_code/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mpu dataframe (RData files can be converted to csv for use with Python)\n",
    "mpu = pyreadr.read_r(file_path + \"data/mpu.RData\")[\"mpu\"]\n",
    "mpu = mpu.rename(columns={'mpu10': 'mpu', 'f10': 'f'})\n",
    "# monthly uncertainty\n",
    "mpu['ym'] = mpu['date'].apply(lambda x: int(x.strftime('%Y%m')))\n",
    "datam = mpu.groupby('ym').agg({'mpu': 'mean', 'f': 'mean'}).reset_index()\n",
    "# quarterly uncertainty\n",
    "mpu['yq'] = mpu['date'].apply(lambda x: int(x.strftime('%Y'))*10 + ((x.month - 1) // 3 + 1))\n",
    "dataq = mpu.groupby('yq').agg({'mpu': 'mean', 'f': 'mean'}).reset_index()\n",
    "# JLN macro uncertainty\n",
    "jln = pd.read_csv(\"data/MacroUncertainty_JLN.csv\")\n",
    "jln['date'] = pd.date_range(start='1960-07-01', periods=len(jln), freq='MS')\n",
    "jln['ym'] = jln['date'].apply(lambda x: int(x.strftime('%Y%m')))\n",
    "jln = jln.drop(['Date'], axis=1)\n",
    "jln.columns = jln.columns.str.replace('=', '_', regex=True)\n",
    "# Merging\n",
    "datam = datam.merge(jln, how='left', on='ym')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real time macro uncertainty - Rogers-Xu\n",
    "rtmu = pd.read_csv(\"data/real_time_MU_RX.csv\", sep=\";\", decimal=\",\", skiprows=1, names=[\"date\", \"mu\"])\n",
    "rtmu['date'] = pd.to_datetime(rtmu['date'])\n",
    "rtmu['ym'] = rtmu['date'].dt.year*100 + rtmu['date'].dt.month\n",
    "rtmu = rtmu.drop(columns=['date'])\n",
    "datam = datam.merge(rtmu, how='left', on='ym')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPF forecast dispersion\n",
    "spf = pd.read_csv(\"data/SPF_Dispersion_PGDP_D2.csv\", sep=\";\", decimal=\",\", na_values=\"#N/A\", skiprows=9)\n",
    "spf.columns = spf.columns.str.replace('[()+]', '.', regex=True)\n",
    "# Replace 'Survey_Date.T.' with the correct column name for your date data\n",
    "spf['year'] = pd.to_numeric(spf['Survey_Date.T.'].str[:4], errors='coerce')\n",
    "spf['quarter'] = pd.to_numeric(spf['Survey_Date.T.'].str[5:6], errors='coerce')\n",
    "# Filter rows where year >= 1990\n",
    "spf = spf[spf['year'] >= 1990]\n",
    "# Create 'yq' column by combining 'year' and 'quarter'\n",
    "spf['yq'] = spf['year']*10 + spf['quarter']\n",
    "# Rename columns\n",
    "spf = spf.rename(columns={\n",
    "    \"PGDP_D2.T.\": \"PGDPD2T\",\n",
    "    \"PGDP_D2.T.1.\": \"PGDPD2T1\",\n",
    "    \"PGDP_D2.T.2.\": \"PGDPD2T2\",\n",
    "    \"PGDP_D2.T.3.\": \"PGDPD2T3\",\n",
    "    \"PGDP_D2.T.4.\": \"PGDPD2T4\"\n",
    "})\n",
    "# Select 'yq' and all columns that start with \"PGDPD2\"\n",
    "spf = spf.loc[:, spf.columns.str.startswith(\"PGDPD2\") | (spf.columns == 'yq')]\n",
    "# Perform left join\n",
    "dataq = pd.merge(dataq, spf, how='left', on='yq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an empty dataframe\n",
    "tbl = pd.DataFrame(np.nan, index=range(8), columns=range(5))\n",
    "# Add data to first column\n",
    "tbl.iloc[:, 0] = [\"Intercept\", \"\", \"Slope\", \"\", \"$R^2$\", \"Observations\", \"Sample\", \"\"]\n",
    "# Define column names\n",
    "tbl.columns = [\"\", \"JLN\", \"JLN\", \"Rogers-Xu\", \"SPF PGDP\"]\n",
    "# Define regression models\n",
    "mods = [\n",
    "    smf.ols(formula='mpu ~ h_12', data=datam).fit(),\n",
    "    smf.ols(formula='mpu ~ h_12', data=datam[datam['date'].dt.year >= 1999]).fit(),\n",
    "    smf.ols(formula='mpu ~ mu', data=datam).fit(),\n",
    "    smf.ols(formula='mpu ~ PGDPD2T4', data=dataq).fit()\n",
    "]\n",
    "\n",
    "for j, mod in enumerate(mods):\n",
    "    se = np.sqrt(mod.get_robustcov_results(cov_type='HAC', maxlags=1).cov_params().diagonal())\n",
    "    coefs = mod.params\n",
    "    r_squared = mod.rsquared\n",
    "    nobs = mod.nobs\n",
    "    \n",
    "    # Store results in tbl dataframe\n",
    "    tbl.iloc[[0, 2], j+1] = [\"{:.2f}\".format(coefs[0]), \"{:.2f}\".format(coefs[1])]  # coeficients\n",
    "    tbl.iloc[[1, 3], j+1] = [\"[{:.2f}]\".format(se[0]), \"[{:.2f}]\".format(se[1])]  # standard errors\n",
    "    tbl.iloc[4, j+1] = round(r_squared, 2)  # R-squared\n",
    "    tbl.iloc[5, j+1] = int(nobs)  # number of observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              JLN               JLN         Rogers-Xu  \\\n",
      "0     Intercept             -0.35             -2.35             -0.55   \n",
      "1                          [0.41]            [0.43]            [0.16]   \n",
      "2         Slope              1.40              3.46             14.07   \n",
      "3                          [0.45]            [0.48]            [1.59]   \n",
      "4         $R^2$              0.04              0.31              0.36   \n",
      "5  Observations               366               258               230   \n",
      "6        Sample           Monthly           Monthly           Monthly   \n",
      "7                1990:M1--2020:M6  1999:M1--2020:M6  1999:M9--2018:10   \n",
      "\n",
      "           SPF PGDP  \n",
      "0              0.47  \n",
      "1            [0.10]  \n",
      "2              0.64  \n",
      "3            [0.14]  \n",
      "4              0.16  \n",
      "5               123  \n",
      "6         Quarterly  \n",
      "7  1990:Q1--2020:Q1  \n"
     ]
    }
   ],
   "source": [
    "# Define the row values\n",
    "tbl.iloc[6, 1:4] = \"Monthly\"\n",
    "tbl.iloc[6, 4] = \"Quarterly\"\n",
    "\n",
    "# Set the date ranges\n",
    "tbl.iloc[7, 1] = \"1990:M1--2020:M6\"\n",
    "tbl.iloc[7, 2] = \"1999:M1--2020:M6\"\n",
    "tbl.iloc[7, 3] = \"1999:M9--2018:10\"\n",
    "tbl.iloc[7, 4] = \"1990:Q1--2020:Q1\"\n",
    "\n",
    "# Print the dataframe\n",
    "print(tbl)\n",
    "\n",
    "# Output the dataframe to a LaTeX table\n",
    "tbl.to_latex(\"output/table_B1.tex\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "econ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
